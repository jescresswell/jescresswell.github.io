---
title: "A Geometric Framework for Understanding Memorization in Generative Models"
collection: publications
permalink: /publication/2024-07-lid-mem
excerpt: 
date: 2024-07-26
authors: 'Brendan Leigh Ross, Hamidreza Kamkari, Zhaoyan Liu, Tongzi Wu, George Stein, Gabriel Loaiza-Ganem, <b>Jesse C. Cresswell</b>'
note:
venueshort: 'ICML 2024 Workshop NGAIS'
venue: 'ICML 2024 Workshop on Geometry-grounded Representation Learning and Generative Modeling'
paperurl: 'https://openreview.net/forum?id=sGHeIefdvL'
pdf: 'https://openreview.net/pdf?id=sGHeIefdvL'
codeurl: 'https://github.com/layer6ai-labs/dgm-geometry'
videourl:
slidesurl:
citation: 'Brendan Leigh Ross, Hamidreza Kamkari, Zhaoyan Liu, Tongzi Wu, George Stein, Gabriel Loaiza-Ganem, Jesse C. Cresswell. A Geometric Framework for Understanding Memorization in Generative Models. ICML 2024 Workshop on Geometry-grounded Representation Learning and Generative Modeling'
---
As deep generative models have progressed, recent work has shown that they are capable of memorizing and reproducing training datapoints when deployed. These findings call into question the usability of generative models, especially in light of the legal and privacy risks brought about by memorization. To better understand this phenomenon, we propose a geometric framework which leverages the manifold hypothesis into a clear language in which to reason about memorization. We propose to analyze memorization in terms of the relationship between the dimensionalities of (i) the ground truth data manifold and (ii) the manifold learned by the model. In preliminary tests on toy examples and Stable Diffusion (Rombach et al., 2022), we show that our theoretical framework accurately describes reality. Furthermore, by analyzing prior work in the context of our geometric framework, we explain and unify assorted observations in the literature and illuminate promising directions for future research on memorization.