---
title: "DRESS: Disentangled Representation-based Self-Supervised Meta-Learning for Diverse Tasks"
collection: publications
permalink: /publication/2024-12-DRESS
excerpt: 
date: 2024-12-14
authors: 'Wei Cui, Tongzi Wu, <b>Jesse C. Cresswell</b>, Yi Sui, Keyvan Golestan'
note:
venueshort: 'NeurIPS 2024 Workshop SSL'
venue: 'NeurIPS 2024 Workshop on Self-Supervised Learning - Theory and Practice'
paperurl: 'https://openreview.net/forum?id=AguQIV9CeN'
pdf: 'https://arxiv.org/pdf/2503.09679'
codeurl: 'https://github.com/layer6ai-labs/DRESS'
videourl:
slidesurl:
citation: 'Wei Cui, Tongzi Wu, Jesse C. Cresswell, Yi Sui, Keyvan Golestan. DRESS: Disentangled Representation-based Self-Supervised Meta-Learning for Diverse Tasks. NeurIPS 2024 Workshop on Self-Supervised Learning - Theory and Practice'
---
Meta-learning represents a strong class of approaches for solving few-shot learning tasks. Nonetheless, recent research suggests that simply pre-training a generic encoder can potentially surpass meta-learning algorithms. In this paper, we first discuss the reasons why meta-learning fails to stand out in these few-shot learning experiments, and hypothesize that it is due to the few-shot learning tasks lacking diversity. We propose DRESS, a task-agnostic Disentangled REpresentation-based Self-Supervised meta-learning approach that enables fast model adaptation on highly diversified few-shot learning tasks. Specifically, DRESS utilizes disentangled representation learning to create self-supervised tasks that can fuel the meta-training process. Furthermore, we also propose a class-partition based metric for quantifying the task diversity directly on the input space. We validate the effectiveness of DRESS through experiments on datasets with multiple factors of variation and varying complexity. The results suggest that DRESS is able to outperform competing methods on the majority of the datasets and task setups. Through this paper, we advocate for a re-examination of proper setups for task adaptation studies, and aim to reignite interest in the potential of meta-learning for solving few-shot learning tasks via disentangled representations.